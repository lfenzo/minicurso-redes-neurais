{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dia3_Redes_Neurais.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDLnA1Ry6wJbbFGRvhrl+9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ObwM6WcEMEeJ"},"source":["# Dia 3: Redes Neurais!\n","\n","Neste notebook você encontrará implementações de Redes Neurais voltadas para Regressão e Classificação utilizando tanto Scikit-Learn quando o Keras/Tensorflow.\n","\n","Utilizaremos dados criados automaticamente assim como os dados disponibilizados dentro do próprio Colab para construir exemplos casos de uso das Redes Neurais. Nestes exemplos iremos fazer as etapas de pré-processamento de forma mais \"direta\" focando na utilização das redes neurais.\n","\n","Para rodar todas as células desse notebook não se esqueça de fazer o upload do arquivo `rice-crop-yield.csv` que está na mesma pasta do drive que os notebooks."]},{"cell_type":"markdown","metadata":{"id":"JNnOstBIM48u"},"source":["## Importando as Bibliotecas\n","\n","Todas as bibliotecas utilizadas nesse notebook serão importadas a seguir:"]},{"cell_type":"code","metadata":{"id":"2Dkql5JiM3ze","executionInfo":{"status":"ok","timestamp":1639588860149,"user_tz":180,"elapsed":3131,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"source":["import keras\n","import joblib\n","import numpy as np\n","import pandas as pd\n","\n","#\n","# métricas de desempenho\n","#\n","\n","# regressão\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","# classificação\n","from sklearn.metrics import accuracy_score, recall_score, f1_score\n","\n","\n","#\n","# classes do scikit-learn relacionadas a redes neurais\n","#\n","\n","# regressão\n","from sklearn.neural_network import MLPRegressor\n","# classificação\n","from sklearn.neural_network import MLPClassifier\n","\n","#\n","# Objetos normalizadores e utilidades para o pre-processamento\n","#\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["As funções abaixo são funções auxiliares para a verificação de performance, eles são utilizadas para evitar que esses código se repitam várias vezes nesse notebook."],"metadata":{"id":"fNU1TPlcaBqW"}},{"cell_type":"code","source":["def verify_performance_regresion(norm_xtrain, norm_xtest, norm_ytrain, norm_ytest, rede_neural, target_scaler):\n","    \n","    norm_pred = rede_neural.predict(norm_xtest)\n","    \n","    valores_reais = target_scaler.inverse_transform(norm_ytest)\n","    valores_preditos = target_scaler.inverse_transform(norm_pred.reshape(-1, 1))\n","    \n","    # \n","    # utilizando as métricas de desempenho do Scikit-Learn para verificar a performance\n","    # \n","    \n","    # dados de teste\n","    print(\"------TESTE------\")\n","    print('MAE \\t=', mean_absolute_error(valores_reais, valores_preditos))\n","    print('MAPE \\t=', mean_absolute_percentage_error(valores_reais, valores_preditos))\n","    print('R2 \\t=', r2_score(valores_reais, valores_preditos))\n","    print()\n","    \n","    # \n","    # dados de treinamento\n","    # \n","    norm_pred_train = rede_neural.predict(norm_xtrain)\n","    \n","    valores_reais_train = target_scaler.inverse_transform(norm_ytrain)\n","    valores_preditos_train = target_scaler.inverse_transform(norm_pred_train.reshape(-1, 1))\n","    \n","    print(\"------TREINAMENTO------\")\n","    print('MAE \\t=', mean_absolute_error(valores_reais_train, valores_preditos_train))\n","    print('MAPE \\t=', mean_absolute_percentage_error(valores_reais_train, valores_preditos_train))\n","    print('R2 \\t=', r2_score(valores_reais_train, valores_preditos_train))\n","\n","    return valores_reais, valores_preditos\n","\n","\n","def verify_performance_classification(xtrain, xtest, ytrain, ytest, rede_neural, target_encoder = None):\n","\n","    pred = rede_neural.predict(xtest)\n","\n","    if isinstance(rede_neural, keras.Sequential):\n","        pred = np.argmax(pred, axis = 1)\n","\n","    # \n","    # utilizando as métricas de desempenho do Scikit-Learn para verificar a performance\n","    # \n","    \n","    # dados de teste\n","    print(\"------TESTE------\")\n","    print('Acurácia: \\t=', accuracy_score(pred, ytest))\n","    print('Recall \\t\\t=', recall_score(pred, ytest, average = 'macro'))\n","    print('F1 Score \\t=', f1_score(pred, ytest, average = 'macro'))\n","    print()\n","    \n","    # \n","    # dados de treinamento\n","    # \n","\n","    pred_train = rede_neural.predict(norm_xtrain)\n","\n","    if isinstance(rede_neural, keras.Sequential):\n","        pred_train = np.argmax(pred_train, axis = 1)\n","\n","    print(\"------TREINAMENTO------\")\n","    print('Acurácia: \\t=', accuracy_score(pred_train, ytrain))\n","    print('Recall \\t\\t=', recall_score(pred_train, ytrain, average = 'macro'))\n","    print('F1 Score \\t=', f1_score(pred_train, ytrain, average = 'macro'))\n","\n","    return ytest, pred\n"],"metadata":{"id":"xlcpLIFEZycD","executionInfo":{"status":"ok","timestamp":1639588860845,"user_tz":180,"elapsed":337,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Regressão\n","\n","Para os problemas de regressão iremos utilizar dois conjuntos de dados:\n","\n","1. California Housing: o mesmo utilizado na etapa de pré-processamento no dia 2 e;\n","\n","1. Diabetes Regression: dataset contendo informações sobre diabetes"],"metadata":{"id":"gGJznhT_JHn0"}},{"cell_type":"markdown","source":["## California Housing\n","\n","\n","Observação: o conjunto de dados \"California Housing\" é disponibilizado em 2 partes dentro do Colab: \"train\" e \"test\". O que faremos é carregar esses dois conjuntos de dados, juntá-los e realizar o pré-preprocessamento como se fossem um, então vamos rodá-los nas redes neurais."],"metadata":{"id":"LGQkO5fTLwZ4"}},{"cell_type":"code","source":["# carregando os dois conjuntos de dados para a memória\n","data1 = pd.read_csv('sample_data/california_housing_train.csv')\n","data2 = pd.read_csv('sample_data/california_housing_test.csv')\n","\n","# juntando os dois conjuntos de dados\n","data = pd.concat((data1, data2), axis = 0)\n","data.reset_index(inplace = True, drop = True)\n","\n","\n","# separação entre dados de atributo alvo\n","target = data['median_house_value']\n","data = data.drop(columns = ['median_house_value'])\n","\n","# realizando a seperação entre treinamento e teste\n","xtrain, xtest, ytrain, ytest = train_test_split(data, target,\n","                                                train_size = 0.85,\n","                                                shuffle = True,\n","                                                random_state = 10)\n","\n","# normalizando os dados utilizando o MinMaxScaler\n","data_scaler = MinMaxScaler()\n","target_scaler = MinMaxScaler()\n","\n","norm_xtrain = data_scaler.fit_transform(xtrain)\n","norm_ytrain = target_scaler.fit_transform(ytrain.values.reshape(-1, 1))\n","\n","norm_xtest = data_scaler.transform(xtest)\n","norm_ytest = target_scaler.transform(ytest.values.reshape(-1, 1))"],"metadata":{"id":"BRgVoboKMEnJ","executionInfo":{"status":"ok","timestamp":1639588865228,"user_tz":180,"elapsed":280,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Scikit-Learn\n","\n","Para a utilização do Scikit-Learn utilizamos a classe `MLPRegressor` de \"Multi-Layer Perceptron Regressor\". Para criar uma rede neural utilizando essa classe basta passar o número de camadadas ocultas (veja também os outros argumentos na documentação, são vários).\n","\n","Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"],"metadata":{"id":"EEsuVQu6OTdm"}},{"cell_type":"code","source":["# criando a rede neural\n","rede_neural = MLPRegressor(hidden_layer_sizes = (150, 150, 30),\n","                           max_iter = 300,\n","                           activation = 'relu',\n","                           solver = 'adam',\n","                           #verbose = True, # remove esse comentário para ver o progresso do treinamento\n","                           alpha = 0.00000005,\n","                           n_iter_no_change = 20,\n","                           early_stopping = True)\n","\n","# para rodar o treinamento da rede neural basta chamar a função fit() com os \n","# conjuntos de dados de treinamento normalizados\n","rede_neural.fit(norm_xtrain, norm_ytrain)\n","\n","print('Rede Neural treinada!')"],"metadata":{"id":"Hgi-N0S_OSC7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["E pronto... Treinamos a primeira rede neural!\n","\n","Em seguida vamos utilizar os dados de treinamento para verificar a performance no teste (e também no treinamento para verificar a existência de *overfit* ou *underfit*.\n","\n","Para isso iremos utilizar os conjuntos de teste e o objeto normalizador do atributo alvo:"],"metadata":{"id":"TZfetWSUPgdI"}},{"cell_type":"code","source":["valores_reais, valores_preditos = verify_performance_regresion(norm_xtrain,\n","                                                               norm_xtest,\n","                                                               norm_ytrain,\n","                                                               norm_ytest,\n","                                                               rede_neural,\n","                                                               target_scaler)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6utZ-ZlPQBW3","executionInfo":{"status":"ok","timestamp":1639589329426,"user_tz":180,"elapsed":424,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"outputId":"f5d518c4-da0e-46c3-f9d4-bca235abda00"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","MAE \t= 35057.83255546599\n","MAPE \t= 0.2036703471976723\n","R2 \t= 0.7979801319827651\n","\n","------TREINAMENTO------\n","MAE \t= 33762.64430013429\n","MAPE \t= 0.18861060400979163\n","R2 \t= 0.8158913062177476\n"]}]},{"cell_type":"markdown","source":["Podemos verificar que os erros no treinamento e no teste são próximos com um erro um pouco maior no teste, que perfeitamente normal. Observamos que o modelo produz um erro médio de 34.000 dolares, que corresponde à aproximadamente 18.8% de erro em relação aos valores esperados.\n","\n","Podemos verificar algumas das previsões feitas \"manualmente\":"],"metadata":{"id":"nAxAI3JqYgx8"}},{"cell_type":"code","source":["print(\"Real\\t\\tPreditos\")\n","\n","for (real, pred) in zip(valores_reais[:15], valores_preditos[:15]):\n","    print(f\"{real}\\t{pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntm44jWzZHCX","executionInfo":{"status":"ok","timestamp":1639589332300,"user_tz":180,"elapsed":308,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"outputId":"fef2cf32-0948-4c5d-8546-fc83e3112192"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Real\t\tPreditos\n","[71100.]\t[74652.74596068]\n","[209900.]\t[189456.961107]\n","[72100.]\t[105029.29454862]\n","[52600.]\t[70952.27759561]\n","[224100.]\t[216287.16195538]\n","[495500.]\t[375224.39733968]\n","[92600.]\t[127245.92686101]\n","[111700.]\t[125799.91786676]\n","[251200.]\t[217628.53193269]\n","[440000.]\t[384891.94198515]\n","[158200.]\t[108399.08463412]\n","[256300.]\t[302529.31828703]\n","[200000.]\t[242732.6858819]\n","[381200.]\t[482695.9203366]\n","[154200.]\t[177508.63788688]\n"]}]},{"cell_type":"markdown","source":["### Keras/Tensorflow\n","\n","O Keras permite que nos tenhamos mais controle sobre a construção da rede neural, mas praticamente todas as opções que estão disponíveis no scikit-learn para o treinamento de redes neurais estão disponíveis no Keras.\n","\n","**Observação**: O keras nos permite utilizar diferentes inicializações para os pesos *w* antes do treinamento. Essa inicialização normalmente é feita em função da função de ativação que estamos utilizando em cada camada. De maneira geral temos a seguinte relação:\n","\n","| Função de Ativação | Inicialização Utilizada |\n","|--------------------|-------------------------|\n","| Identidade (linaer), tanh, logistica, softmax | glorot |\n","| ReLU | He |\n","| SELU | LeCun |"],"metadata":{"id":"8nXqIVu4ahfK"}},{"cell_type":"code","source":["rede_neural = keras.Sequential([\n","    keras.layers.Dense(units = 150,\n","                       activation = 'relu',\n","                       kernel_initializer = 'he_normal'),\n","\n","    keras.layers.Dense(units = 150,\n","                       activation = 'relu',\n","                       kernel_initializer = 'he_normal'),\n","\n","    keras.layers.Dense(units = 30,\n","                       activation = 'relu',\n","                       kernel_initializer = 'he_normal'),\n","\n","    keras.layers.Dense(units = 1,\n","                       activation = 'relu',\n","                       kernel_initializer = 'he_normal'),\n","])\n","\n","rede_neural.compile(\n","    loss = 'mse',\n","    optimizer = 'adam',\n",")\n","\n","rede_neural.fit(x = norm_xtrain,\n","                y = norm_ytrain,\n","                epochs = 100,\n","                shuffle = True,\n","                #verbose = 1, # retire o comentário dessa linha para ver a progressão do treinamento\n","                validation_split = 0.1,\n","                callbacks = keras.callbacks.EarlyStopping(patience = 20))"],"metadata":{"id":"_ZVUlFEAa_Vo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explicação**: as redes neurais feitas com Keras devem ser construidas camada a camada (ao contrário do Scikit-Learn que eles são especificadas todas de uma vez). Isso permite que diferentes especificações sejam passadas por camada como é feito no código acima.\n","\n","Uma vez que a rede neural é instanciada ela deve ser **compilada** por meio do método `.compile()` que recebe uma função de custo `loss` e um otimizador `optimizer`. Depois que o modelo foi compilado ele estará pronto para o treinamento. Para utilizar o **Early Stopping* é preciso passar como argumento `callbacks` do método `.fit()` o objeto `keras.callbacks.EarlyStopping()`."],"metadata":{"id":"gkqUQN5_cLS6"}},{"cell_type":"code","source":["valores_reais, valores_preditos = verify_performance_regresion(norm_xtrain,\n","                                                               norm_xtest,\n","                                                               norm_ytrain,\n","                                                               norm_ytest,\n","                                                               rede_neural,\n","                                                               target_scaler)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er0-RDf3b6Ku","executionInfo":{"status":"ok","timestamp":1639590347091,"user_tz":180,"elapsed":1063,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"outputId":"2d6b0ea2-7d7e-4144-a9e0-7b4936055103"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","MAE \t= 36325.51135872396\n","MAPE \t= 0.21524329201939865\n","R2 \t= 0.7892349581184859\n","\n","------TREINAMENTO------\n","MAE \t= 33351.57224494485\n","MAPE \t= 0.1936243162005948\n","R2 \t= 0.83430905748064\n"]}]},{"cell_type":"markdown","source":["Vamos inspecionar algumas das previsões feitas pelo modelo:"],"metadata":{"id":"WqUy7N7yZXYg"}},{"cell_type":"code","source":["print(\"Real\\t\\tPrevisto\")\n","\n","for (real, pred) in zip(valores_reais[:15], valores_preditos[:15]):\n","    print(f\"{real}\\t{pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639590406504,"user_tz":180,"elapsed":8,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"outputId":"ab1b3bb3-d3c1-4d0a-b25e-3b6cfabec684","id":"rGXg76MPZf8r"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Real\t\tPrevisto\n","[71100.]\t[87389.58]\n","[209900.]\t[218636.05]\n","[72100.]\t[118669.6]\n","[52600.]\t[71001.54]\n","[224100.]\t[238646.25]\n","[495500.]\t[359401.47]\n","[92600.]\t[136276.08]\n","[111700.]\t[143836.16]\n","[251200.]\t[255384.53]\n","[440000.]\t[387982.34]\n","[158200.]\t[140045.33]\n","[256300.]\t[324671.72]\n","[200000.]\t[302413.8]\n","[381200.]\t[499382.88]\n","[154200.]\t[205473.6]\n"]}]},{"cell_type":"markdown","source":["## Rice Crop Yield\n","\n","Para adicionar esse conjunto de dados vá na aba \"Files\" no canto esquerdo da tela, nela haverá 3 botões na parte superior, clique no primeiro botão da esqerda para a direita (\"*Upload to Session Storage*\") então selecione o conjunto de dados presente na pasta compartilhada do drive \"rice-crop-yield.csv\". Uma vez que ele for carregado ele deverá aparecer na seção de \"Arquivos\" dentro do Colab.\n"],"metadata":{"id":"GsHFaKgMP6tn"}},{"cell_type":"code","source":["# \n","# carregando o conjunto de dados\n","# \n","df = pd.read_csv(\"./rice-crop-yield.csv\")\n","\n","# deletando colunas desnecessárias (verificado anteriormente)\n","columns_to_delete = [\n","    \"FLUVENTS\",\n","    \"DYSTROPEPTS\",\n","    \"ORTHENTS\",\n","    \"UDALFS\",\n","    \"USTALFS\",\n","]\n","\n","df.drop(columns = columns_to_delete, inplace = True) \n","\n","target = df['RICE_YIELD']\n","data = df.drop(columns = ['RICE_YIELD'])\n","\n","# separação entre treinamento e teste\n","xtrain, xtest, ytrain, ytest = train_test_split(data, target,\n","                                                train_size = 0.9,\n","                                                shuffle = True)\n","\n","# normalização dos conjuntosde treinamento\n","data_scaler = MinMaxScaler()\n","target_scaler = MinMaxScaler()\n","\n","norm_xtrain = data_scaler.fit_transform(xtrain)\n","norm_ytrain = target_scaler.fit_transform(ytrain.values.reshape(-1, 1))\n","\n","norm_xtest = data_scaler.transform(xtest)\n","norm_ytest = target_scaler.transform(ytest.values.reshape(-1, 1))\n"],"metadata":{"id":"-SHbTFU8ZPsk","executionInfo":{"status":"ok","timestamp":1639590442027,"user_tz":180,"elapsed":720,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Para verificar que tudo saiu como o esperado podemos verificar os formatos (*shapes*) dos conjuntos de dados:\n","\n","Podemos ver que teremos 397 amostras para treinamento e 45 para o teste da rede neural."],"metadata":{"id":"p2c9QT-3NKh3"}},{"cell_type":"code","source":["print(\"dados de treinamento\")\n","print(norm_xtrain.shape)\n","print(norm_ytrain.shape)\n","\n","print(\"\\ndados de teste\")\n","print(norm_xtest.shape)\n","print(norm_ytest.shape)"],"metadata":{"id":"3t-R4m7zNSZW","executionInfo":{"status":"ok","timestamp":1639590563687,"user_tz":180,"elapsed":12,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"39229c0d-cdd0-4943-e181-f62f0cf29300"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["dados de treinamento\n","(2282, 16)\n","(2282, 1)\n","\n","dados de teste\n","(254, 16)\n","(254, 1)\n"]}]},{"cell_type":"markdown","source":["Podemos também observar esse conjunto de dados plotando os valores gerados automaticamente:"],"metadata":{"id":"4nVuESsdPT9N"}},{"cell_type":"markdown","source":["### Scikit-Learn\n"],"metadata":{"id":"vFVFaPL2NemE"}},{"cell_type":"code","source":["rede_neural = MLPRegressor(hidden_layer_sizes = (700, 500, 200, 50),\n","                           max_iter = 1000,\n","                           solver = 'adam',\n","                           verbose = True,\n","                           early_stopping = False,\n","                           alpha = 0.0)\n","\n","rede_neural.fit(norm_xtrain, norm_ytrain)"],"metadata":{"id":"8vC04C7JNzXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valores_reais, valores_preditos = verify_performance_regresion(norm_xtrain,\n","                                                               norm_xtest,\n","                                                               norm_ytrain,\n","                                                               norm_ytest,\n","                                                               rede_neural,\n","                                                               target_scaler)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1639590781593,"user_tz":180,"elapsed":314,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"id":"iX6SOorVPASR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e83a9060-4133-4d16-b2fd-da5f3237dfa3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","MAE \t= 328.0398621269067\n","MAPE \t= 0.1613196313547117\n","R2 \t= 0.725124660725552\n","\n","------TREINAMENTO------\n","MAE \t= 303.9548212517202\n","MAPE \t= 0.14457598957402246\n","R2 \t= 0.7354486240788147\n"]}]},{"cell_type":"markdown","source":["**ATENÇÂO!!!** Note os valores dos erros no teste e no treinamento, veja que eles são muito discrepantes. Trata-se de um exemplo de **overfit**. Os dados de treinamento são super ajustados: o modelo tem um erro muito menor no treinamento do que no teste e o erro no teste é muito pequeno.\n","\n","Para resolver esse problema temos algumas abordagens⁉\n","1. adicionar `EarlyStopping`aumentando o valor da tolerancia `tol`\n","1. Aumentar o valor de `alpha`(fator de regularização)\n","1. Diminuir a complexidade do modelo reduzindo o número de neuronios e camadas ocultas\n","\n","Na execução a seguir irei utilizar as opções 1, 2 e 3:"],"metadata":{"id":"kNNceI77nzXP"}},{"cell_type":"code","source":["rede_neural = MLPRegressor(hidden_layer_sizes = (300, 150, 40),\n","                           max_iter = 200,\n","                           solver = 'adam',\n","                           activation = 'relu',\n","                           verbose = True, # remove esse comentário para ver o progresso do treinamento\n","                           early_stopping = True,\n","                           tol = 1e-4,\n","                           n_iter_no_change = 20,\n","                           alpha = 2e-4)\n","\n","rede_neural.fit(norm_xtrain, norm_ytrain)"],"metadata":{"id":"33sn920uo4VF","executionInfo":{"status":"ok","timestamp":1639590457007,"user_tz":180,"elapsed":4721,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c945738-6e93-41d7-d763-a84a523214e4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.01603415\n","Validation score: 0.295431\n","Iteration 2, loss = 0.00942225\n","Validation score: 0.378084\n","Iteration 3, loss = 0.00866794\n","Validation score: 0.433579\n","Iteration 4, loss = 0.00786856\n","Validation score: 0.458325\n","Iteration 5, loss = 0.00747294\n","Validation score: 0.468719\n","Iteration 6, loss = 0.00718734\n","Validation score: 0.480622\n","Iteration 7, loss = 0.00697417\n","Validation score: 0.504057\n","Iteration 8, loss = 0.00670991\n","Validation score: 0.480989\n","Iteration 9, loss = 0.00664087\n","Validation score: 0.489163\n","Iteration 10, loss = 0.00637255\n","Validation score: 0.522630\n","Iteration 11, loss = 0.00617893\n","Validation score: 0.539085\n","Iteration 12, loss = 0.00601407\n","Validation score: 0.544969\n","Iteration 13, loss = 0.00590054\n","Validation score: 0.561850\n","Iteration 14, loss = 0.00574850\n","Validation score: 0.558724\n","Iteration 15, loss = 0.00570148\n","Validation score: 0.560338\n","Iteration 16, loss = 0.00567418\n","Validation score: 0.545190\n","Iteration 17, loss = 0.00551257\n","Validation score: 0.577334\n","Iteration 18, loss = 0.00535852\n","Validation score: 0.543221\n","Iteration 19, loss = 0.00543756\n","Validation score: 0.550612\n","Iteration 20, loss = 0.00527253\n","Validation score: 0.565743\n","Iteration 21, loss = 0.00514483\n","Validation score: 0.557864\n","Iteration 22, loss = 0.00513641\n","Validation score: 0.583962\n","Iteration 23, loss = 0.00531390\n","Validation score: 0.579363\n","Iteration 24, loss = 0.00512609\n","Validation score: 0.552552\n","Iteration 25, loss = 0.00519960\n","Validation score: 0.565645\n","Iteration 26, loss = 0.00535655\n","Validation score: 0.587484\n","Iteration 27, loss = 0.00552012\n","Validation score: 0.581060\n","Iteration 28, loss = 0.00492877\n","Validation score: 0.578645\n","Iteration 29, loss = 0.00480257\n","Validation score: 0.590246\n","Iteration 30, loss = 0.00476137\n","Validation score: 0.558611\n","Iteration 31, loss = 0.00514872\n","Validation score: 0.582460\n","Iteration 32, loss = 0.00498103\n","Validation score: 0.585076\n","Iteration 33, loss = 0.00514362\n","Validation score: 0.585844\n","Iteration 34, loss = 0.00501080\n","Validation score: 0.583879\n","Iteration 35, loss = 0.00470477\n","Validation score: 0.587023\n","Iteration 36, loss = 0.00463354\n","Validation score: 0.585954\n","Iteration 37, loss = 0.00472222\n","Validation score: 0.549484\n","Iteration 38, loss = 0.00462067\n","Validation score: 0.609119\n","Iteration 39, loss = 0.00446711\n","Validation score: 0.575655\n","Iteration 40, loss = 0.00453088\n","Validation score: 0.538000\n","Iteration 41, loss = 0.00500154\n","Validation score: 0.583817\n","Iteration 42, loss = 0.00454735\n","Validation score: 0.585908\n","Iteration 43, loss = 0.00452761\n","Validation score: 0.574857\n","Iteration 44, loss = 0.00441413\n","Validation score: 0.604393\n","Iteration 45, loss = 0.00440820\n","Validation score: 0.592353\n","Iteration 46, loss = 0.00445225\n","Validation score: 0.589537\n","Iteration 47, loss = 0.00438139\n","Validation score: 0.591953\n","Iteration 48, loss = 0.00434769\n","Validation score: 0.599412\n","Iteration 49, loss = 0.00466360\n","Validation score: 0.585521\n","Iteration 50, loss = 0.00447339\n","Validation score: 0.609605\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPRegressor(alpha=0.0002, early_stopping=True,\n","             hidden_layer_sizes=(300, 150, 40), n_iter_no_change=20,\n","             verbose=True)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["valores_reais, valores_preditos = verify_performance_regresion(norm_xtrain,\n","                                                               norm_xtest,\n","                                                               norm_ytrain,\n","                                                               norm_ytest,\n","                                                               rede_neural,\n","                                                               target_scaler)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1639590931099,"user_tz":180,"elapsed":310,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"id":"eCUtBrwzpM-A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd648174-7987-4dc6-e53a-656776e7e06d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","MAE \t= 328.0398621269067\n","MAPE \t= 0.1613196313547117\n","R2 \t= 0.725124660725552\n","\n","------TREINAMENTO------\n","MAE \t= 303.9548212517202\n","MAPE \t= 0.14457598957402246\n","R2 \t= 0.7354486240788147\n"]}]},{"cell_type":"markdown","source":["Note que não apenas os erros no treinamento foram mais próximos dos erros no teste, mas também que os erros no teste foram menores no modelo sem overfit do que no modelo sofrendo de overfit.\n","\n","Podemos também verificar essas previsões \"manualmente\":"],"metadata":{"id":"9qAIv87bscJp"}},{"cell_type":"code","source":["print(\"Real\\t\\tPrevisto\")\n","\n","for (real, pred) in zip(valores_reais[:15], valores_preditos[:15]):\n","    print(f\"{real}\\t{pred}\")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1639590988957,"user_tz":180,"elapsed":1036,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"id":"rAbka0n5tE6N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eee93f5d-2d74-4c8d-ad5a-5fbbdb186296"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Real\t\tPrevisto\n","[1005.7]\t[1659.02485405]\n","[3409.52]\t[2195.87102983]\n","[2273.69]\t[2610.03868849]\n","[1730.42]\t[1430.69279949]\n","[2599.86]\t[2527.7036245]\n","[2369.86]\t[2423.03197676]\n","[2590.07]\t[2018.53785041]\n","[1464.77]\t[1667.10252788]\n","[4053.89]\t[3540.25217236]\n","[2616.91]\t[2662.28228593]\n","[2545.1]\t[2109.87149676]\n","[2239.75]\t[2445.76395369]\n","[1501.46]\t[1807.89237392]\n","[2018.02]\t[2028.29560135]\n","[1552.67]\t[2163.41258395]\n"]}]},{"cell_type":"markdown","source":["### Keras/Tensorflow"],"metadata":{"id":"P7pD8Oyj_vbw"}},{"cell_type":"code","source":["rede_neural = keras.Sequential([\n","    keras.layers.Dense(100, activation = 'relu', kernel_initializer = 'he_normal'),\n","\n","    keras.layers.Dense(100, activation = 'relu', kernel_initializer = 'he_normal'),\n","\n","    keras.layers.Dense(20, activation = 'relu', kernel_initializer = 'he_normal'),\n","\n","    # camada de saída\n","    keras.layers.Dense(1, activation = 'relu', kernel_initializer = 'he_normal'),\n","])\n","\n","rede_neural.compile(\n","   loss = 'mse',\n","   optimizer = 'adam'\n",")\n","\n","rede_neural.fit(norm_xtrain, norm_ytrain,\n","                validation_split = 0.15,\n","                shuffle = True,\n","                epochs = 500,\n","                callbacks = keras.callbacks.EarlyStopping(patience = 20))"],"metadata":{"id":"cdMebuyq_re6","executionInfo":{"status":"ok","timestamp":1639591206568,"user_tz":180,"elapsed":24594,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3670fb8-2262-4d29-e9a0-65b93ca1d826"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","61/61 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0164\n","Epoch 2/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0140\n","Epoch 3/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0140\n","Epoch 4/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0122\n","Epoch 5/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0115\n","Epoch 6/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0112\n","Epoch 7/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0111\n","Epoch 8/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0125\n","Epoch 9/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0103\n","Epoch 10/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0102\n","Epoch 11/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0100\n","Epoch 12/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0110\n","Epoch 13/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0102\n","Epoch 14/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0101\n","Epoch 15/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0107\n","Epoch 16/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0094\n","Epoch 17/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0094\n","Epoch 18/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0095\n","Epoch 19/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0099\n","Epoch 20/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0093\n","Epoch 21/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0097\n","Epoch 22/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0096\n","Epoch 23/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0113\n","Epoch 24/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0097\n","Epoch 25/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0099\n","Epoch 26/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0092\n","Epoch 27/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0105\n","Epoch 28/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n","Epoch 29/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0092\n","Epoch 30/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0090\n","Epoch 31/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0089\n","Epoch 32/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0088\n","Epoch 33/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0093\n","Epoch 34/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0088\n","Epoch 35/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0088\n","Epoch 36/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0085\n","Epoch 37/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0092\n","Epoch 38/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0096\n","Epoch 39/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0086\n","Epoch 40/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0089\n","Epoch 41/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0089\n","Epoch 42/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0088\n","Epoch 43/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0086\n","Epoch 44/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0104\n","Epoch 45/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0085\n","Epoch 46/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0086\n","Epoch 47/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0089\n","Epoch 48/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0088\n","Epoch 49/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0083\n","Epoch 50/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0085\n","Epoch 51/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0103\n","Epoch 52/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0084\n","Epoch 53/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0082\n","Epoch 54/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0087\n","Epoch 55/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0089\n","Epoch 56/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0095\n","Epoch 57/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0084\n","Epoch 58/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0104\n","Epoch 59/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0089\n","Epoch 60/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0089\n","Epoch 61/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0082\n","Epoch 62/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0085\n","Epoch 63/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0082\n","Epoch 64/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0093\n","Epoch 65/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0090\n","Epoch 66/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0093\n","Epoch 67/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0085\n","Epoch 68/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0080\n","Epoch 69/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0085\n","Epoch 70/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0082\n","Epoch 71/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0084\n","Epoch 72/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0081\n","Epoch 73/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0081\n","Epoch 74/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0084\n","Epoch 75/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0094\n","Epoch 76/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0086\n","Epoch 77/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0083\n","Epoch 78/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0080\n","Epoch 79/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0084\n","Epoch 80/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0081\n","Epoch 81/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0083\n","Epoch 82/500\n","61/61 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0080\n","Epoch 83/500\n","61/61 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0118\n","Epoch 84/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0082\n","Epoch 85/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0094\n","Epoch 86/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0081\n","Epoch 87/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0095\n","Epoch 88/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0083\n","Epoch 89/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0094\n","Epoch 90/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0085\n","Epoch 91/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0082\n","Epoch 92/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0081\n","Epoch 93/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0094\n","Epoch 94/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0092\n","Epoch 95/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0081\n","Epoch 96/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0079\n","Epoch 97/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0077\n","Epoch 98/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0078\n","Epoch 99/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0079\n","Epoch 100/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0080\n","Epoch 101/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0078\n","Epoch 102/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0081\n","Epoch 103/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0083\n","Epoch 104/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0077\n","Epoch 105/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0077\n","Epoch 106/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0080\n","Epoch 107/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0087\n","Epoch 108/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0075\n","Epoch 109/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0084\n","Epoch 110/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0088\n","Epoch 111/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0083\n","Epoch 112/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0080\n","Epoch 113/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0082\n","Epoch 114/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0078\n","Epoch 115/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0077\n","Epoch 116/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0077\n","Epoch 117/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0080\n","Epoch 118/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0076\n","Epoch 119/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0086\n","Epoch 120/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0087\n","Epoch 121/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0078\n","Epoch 122/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0075\n","Epoch 123/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0076\n","Epoch 124/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0083\n","Epoch 125/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0083\n","Epoch 126/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0082\n","Epoch 127/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0080\n","Epoch 128/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0081\n","Epoch 129/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0074\n","Epoch 130/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0080\n","Epoch 131/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0084\n","Epoch 132/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0089\n","Epoch 133/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0081\n","Epoch 134/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0078\n","Epoch 135/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0076\n","Epoch 136/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0076\n","Epoch 137/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0078\n","Epoch 138/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0080\n","Epoch 139/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0075\n","Epoch 140/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0083\n","Epoch 141/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0087\n","Epoch 142/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0079\n","Epoch 143/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0084\n","Epoch 144/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0079\n","Epoch 145/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0076\n","Epoch 146/500\n","61/61 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0081\n","Epoch 147/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0085\n","Epoch 148/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0082\n","Epoch 149/500\n","61/61 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0088\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb829a47a90>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["valores_reais, valores_preditos = verify_performance_regresion(norm_xtrain,\n","                                                               norm_xtest,\n","                                                               norm_ytrain,\n","                                                               norm_ytest,\n","                                                               rede_neural,\n","                                                               target_scaler)"],"metadata":{"id":"So3koeiNBLhb","executionInfo":{"status":"ok","timestamp":1639591268671,"user_tz":180,"elapsed":32035,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a19bebb-72d2-4c7e-a534-8b1f7f721762"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","MAE \t= 323.0941646353654\n","MAPE \t= 0.16326313525069552\n","R2 \t= 0.7371779278586683\n","\n","------TREINAMENTO------\n","MAE \t= 266.4144016115421\n","MAPE \t= 0.13212247322067874\n","R2 \t= 0.7834855337790184\n"]}]},{"cell_type":"markdown","source":["# Classificação\n","\n","Para problemas de classificação utilizaremos 3 datasets sendo eles:\n","\n","1. MNIST Digits: dataset contendo digitos escritos à mão\n","\n","1. Covertype: dataset com caracteristicas de covertura vegetal de diversas localidades nos Estados Unidos."],"metadata":{"id":"rMEwncW-KrPa"}},{"cell_type":"markdown","source":["## MNIST Handwritten Digits\n","\n","O datasets MNIST é um dataset contendo diversas imagens de resolução 28 por 28 de números escritos à mão. Ao todo há no treinamento 20.000 amostras disponíveis, neste caso cada um dos pixels da imagem se torna um atributo a partir do qual a rede deve aprender. Por se tratar de dados obtidos a partir de imagens a incidência de valores faltantes vai praticamente a zero, mesmo assim é necessário normalizar os valores de cada um dos atributos.\n","\n","\n","Na célula abaixo vemos exemplos dessas imagens:"],"metadata":{"id":"_Q_D6egtKNaf"}},{"cell_type":"code","metadata":{"id":"NV2mwzc2L5aO","executionInfo":{"status":"ok","timestamp":1639591740591,"user_tz":180,"elapsed":9769,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/","height":729},"outputId":"1c4c4614-369c-4df2-9df9-b97c0696c516"},"source":["import matplotlib.pyplot as plt\n","\n","# carregando conjunto de dados\n","data = pd.read_csv('./sample_data/mnist_train_small.csv', header = None)\n","\n","# crianto a plot onde os números serão apresentados\n","fig, axs = plt.subplots(5, 5, figsize = (10, 10))\n","\n","cont = 0\n","for i in range(5):\n","    for j in range(5):\n","        label = data.iloc[cont, 0]\n","        sample = data.iloc[cont, 1:].values.reshape(28, 28)\n","        cont += 1\n","        axs[i, j].imshow(sample)\n","        axs[i, j].set_title(f'label = {label}')\n","        axs[i, j].axis('off')\n","\n","fig.tight_layout()"],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 25 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Podemos verificar também outras informações sobre esse conjunto de dado. Uma delas é a contagem de imagens por número, ou seja, quantas imagens de cada dígito exitem no dataset:"],"metadata":{"id":"JKkGwBWXTMdx"}},{"cell_type":"code","source":["# há mais amostras com 1, 7 e 6 do que 5, 8 e 4...\n","data.iloc[:, 0].value_counts()"],"metadata":{"id":"CcBrEK9nTTjf","executionInfo":{"status":"ok","timestamp":1639591740593,"user_tz":180,"elapsed":22,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa227e34-d674-4b49-f627-81724c5ded7a"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    2243\n","7    2126\n","6    2039\n","9    2023\n","3    2021\n","2    1989\n","0    1962\n","4    1924\n","8    1912\n","5    1761\n","Name: 0, dtype: int64"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# carregando o conjunto de dados\n","# como os conjuntos já foram separados em arquivos diferentes podemos carregá-los direto\n","# para as variáveis xtrain, ytrain, etc...\n","\n","# dados de treinamento\n","all_mnist = pd.read_csv('./sample_data/mnist_train_small.csv', header = None)\n","xtrain = all_mnist.iloc[:, 1:]\n","ytrain = all_mnist.iloc[:, 0]\n","\n","# dados de teste\n","test_mnist = pd.read_csv(\"./sample_data/mnist_test.csv\", header = None)\n","xtest = test_mnist.iloc[:, 1:]\n","ytest = test_mnist.iloc[:, 0]"],"metadata":{"id":"7mOmnK14Octf","executionInfo":{"status":"ok","timestamp":1639591742111,"user_tz":180,"elapsed":1534,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["Note que ao lermos os dados utilizando a função `pd.read_csv()` estamos utilizando a opção `header = None`. Isso ocorre porque o conjunto de dados não possui um cabeçalho com os nomes dos atributos, quando esse é o caso podemos passar o argumento `header = None` para que nomes genéricos (neste caso: `1`, `2`, `3`, ...) sejam atribuidos automaticamente a cada um dos atributos.\n","\n","Os valores presentes nesse conjunto de dados estão no intervalo [0, 255] por isso é necessário normalizá-los para a execução do treinamento das redes neurais. No entanto não será necessário normalizar o atributo alvo (já veremos o por quê)...\n"],"metadata":{"id":"tOTi_1C-P34l"}},{"cell_type":"code","source":["data_scaler = MinMaxScaler()\n","\n","norm_xtrain = data_scaler.fit_transform(xtrain)\n","norm_xtest = data_scaler.transform(xtest)"],"metadata":{"id":"m7HFldhJQCOo","executionInfo":{"status":"ok","timestamp":1639591745699,"user_tz":180,"elapsed":313,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["### Scikit-Learn\n","\n","Para utilizar uma rede neral para classificação devemos utilizar a classe `MLPClassifier`, (assim como utilizamos a veriante \"regressor\" anteriormente para os problemas de regressão). Neste caso os parâmetros utilizados são os mesmos, mas utilizados em uma rede que desempenhará uma tarefa de classificação."],"metadata":{"id":"vJ9EOL8qSylJ"}},{"cell_type":"code","source":["rede_neural = MLPClassifier(hidden_layer_sizes = (256, 256, 32),\n","                            solver = 'adam',\n","                            early_stopping = True,\n","                            max_iter = 500,\n","                            verbose = True, # retire o comentário dessa linha para ver o progresso de treinameno\n","                            activation = 'relu')\n","\n","rede_neural.fit(norm_xtrain, ytrain)"],"metadata":{"id":"arXaXGBBQ-T2","executionInfo":{"status":"ok","timestamp":1639591809504,"user_tz":180,"elapsed":58099,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5f3df0c-7f85-4904-83f9-640cf82b5eb1"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.54856116\n","Validation score: 0.931000\n","Iteration 2, loss = 0.19401212\n","Validation score: 0.949500\n","Iteration 3, loss = 0.13580831\n","Validation score: 0.956000\n","Iteration 4, loss = 0.09832086\n","Validation score: 0.958000\n","Iteration 5, loss = 0.07287170\n","Validation score: 0.965000\n","Iteration 6, loss = 0.04826722\n","Validation score: 0.964500\n","Iteration 7, loss = 0.03912898\n","Validation score: 0.966500\n","Iteration 8, loss = 0.02658425\n","Validation score: 0.965500\n","Iteration 9, loss = 0.01955680\n","Validation score: 0.967000\n","Iteration 10, loss = 0.01676378\n","Validation score: 0.966500\n","Iteration 11, loss = 0.01204663\n","Validation score: 0.966000\n","Iteration 12, loss = 0.00897888\n","Validation score: 0.972000\n","Iteration 13, loss = 0.00835546\n","Validation score: 0.967500\n","Iteration 14, loss = 0.00482383\n","Validation score: 0.971000\n","Iteration 15, loss = 0.00293047\n","Validation score: 0.968000\n","Iteration 16, loss = 0.00216157\n","Validation score: 0.971500\n","Iteration 17, loss = 0.00133259\n","Validation score: 0.972000\n","Iteration 18, loss = 0.00097155\n","Validation score: 0.971500\n","Iteration 19, loss = 0.00082782\n","Validation score: 0.973000\n","Iteration 20, loss = 0.00075501\n","Validation score: 0.973500\n","Iteration 21, loss = 0.00069891\n","Validation score: 0.972500\n","Iteration 22, loss = 0.00064212\n","Validation score: 0.973000\n","Iteration 23, loss = 0.00060822\n","Validation score: 0.973000\n","Iteration 24, loss = 0.00057583\n","Validation score: 0.972500\n","Iteration 25, loss = 0.00054492\n","Validation score: 0.973500\n","Iteration 26, loss = 0.00051947\n","Validation score: 0.972000\n","Iteration 27, loss = 0.00049640\n","Validation score: 0.972000\n","Iteration 28, loss = 0.00047631\n","Validation score: 0.973500\n","Iteration 29, loss = 0.00045763\n","Validation score: 0.973000\n","Iteration 30, loss = 0.00044382\n","Validation score: 0.973000\n","Iteration 31, loss = 0.00043048\n","Validation score: 0.973000\n","Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 256, 32),\n","              max_iter=500, verbose=True)"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["Uma vez que a rede neural foi treinada podemos utilizar a função `verify_performance_classification()` para observarmos as métricas de Acurácia, *Racall* e *F1Score* do modelo que acabamos de treinar."],"metadata":{"id":"uojX82KKW-HM"}},{"cell_type":"code","source":["classes_esperadas, classes_preditas = verify_performance_classification(norm_xtrain,\n","                                                                        norm_xtest,\n","                                                                        ytrain,\n","                                                                        ytest,\n","                                                                        rede_neural)"],"metadata":{"id":"TeMijveHVT1u","executionInfo":{"status":"ok","timestamp":1639591827515,"user_tz":180,"elapsed":1093,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c7ae876-e06c-4644-d8f2-fb05e1e7d958"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","Acurácia: \t= 0.9718\n","Recall \t\t= 0.9716736865095728\n","F1 Score \t= 0.9715443632469721\n","\n","------TREINAMENTO------\n","Acurácia: \t= 0.99735\n","Recall \t\t= 0.9973398860273897\n","F1 Score \t= 0.9973347285745298\n"]}]},{"cell_type":"markdown","source":["### Keras/Tensorflow\n","\n","Para utilizar o Keras para problemas de classificação não precisamos instanciar uma classe diferente da que utilizamos na regressão. Entretanto, devemos fazer algumas alterações na rede neural para que a rede possa ser traineda para realizar a classificação.\n","\n","As mudanças que devemos fazer na Rede Neural são:\n","\n","1. alterar a função de custo passada para o parâmetro `loss` no momento de compilar a rede no método `.compile()`.\n","\n","1. Adicionar neurônios na camada de saída de forma que a quantidade de neurônios de saída seja a mesma quantidade de classes do problema (no caso no MNIST são 10 digitos possíveis -- 10 classes -- então devemos ter 10 neurôios na última camada)\n","\n","1. alterar a função de ativação da última camada (camada de saída)\n"],"metadata":{"id":"l4vzr6VpX916"}},{"cell_type":"code","source":["rede_neural = keras.Sequential([\n","    keras.layers.Flatten(),\n","\n","    keras.layers.Dense(256, activation = 'relu', kernel_initializer = 'he_normal'),\n","    keras.layers.Dense(32, activation = 'relu', kernel_initializer = 'he_normal'),\n","\n","    # camada de saída com 10 neurônios (1 para cada número)\n","    keras.layers.Dense(10, activation = 'softmax'),\n","])\n","\n","rede_neural.compile(\n","    loss = 'sparse_categorical_crossentropy',\n","    optimizer = 'adam',\n","    metrics = ['accuracy'],\n",")\n","\n","rede_neural.fit(norm_xtrain, ytrain,\n","                epochs = 100,\n","                validation_split = 0.1,\n","                callbacks = keras.callbacks.EarlyStopping(patience = 10))"],"metadata":{"id":"UJlt1wSWZLaj","executionInfo":{"status":"ok","timestamp":1639592198271,"user_tz":180,"elapsed":24782,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ffe96eca-6c6e-4e51-ea08-99d4c588bfef"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.3826 - accuracy: 0.8893 - val_loss: 0.2218 - val_accuracy: 0.9350\n","Epoch 2/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.1595 - accuracy: 0.9516 - val_loss: 0.1646 - val_accuracy: 0.9505\n","Epoch 3/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.1063 - accuracy: 0.9692 - val_loss: 0.1476 - val_accuracy: 0.9590\n","Epoch 4/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.1326 - val_accuracy: 0.9590\n","Epoch 5/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0470 - accuracy: 0.9869 - val_loss: 0.1489 - val_accuracy: 0.9565\n","Epoch 6/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.1520 - val_accuracy: 0.9560\n","Epoch 7/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.1484 - val_accuracy: 0.9600\n","Epoch 8/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1833 - val_accuracy: 0.9485\n","Epoch 9/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.1524 - val_accuracy: 0.9625\n","Epoch 10/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1846 - val_accuracy: 0.9585\n","Epoch 11/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.1472 - val_accuracy: 0.9610\n","Epoch 12/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.1606 - val_accuracy: 0.9645\n","Epoch 13/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.1663 - val_accuracy: 0.9575\n","Epoch 14/100\n","563/563 [==============================] - 2s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1862 - val_accuracy: 0.9585\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb827adc0d0>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["classes_esperadas, classes_preditas = verify_performance_classification(norm_xtrain,\n","                                                                        norm_xtest,\n","                                                                        ytrain,\n","                                                                        ytest,\n","                                                                        rede_neural)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1639592258221,"user_tz":180,"elapsed":37177,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"id":"bTA2Tp9MenLL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5be4438-104d-4e40-d974-73e7ac018513"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","Acurácia: \t= 0.9656\n","Recall \t\t= 0.9658883764330559\n","F1 Score \t= 0.9653382066568656\n","\n","------TREINAMENTO------\n","Acurácia: \t= 0.98975\n","Recall \t\t= 0.9898612747085613\n","F1 Score \t= 0.9896399468679252\n"]}]},{"cell_type":"markdown","source":["## Vegetation Covertypes\n","\n","Dataset contendo informações tais como elevação, tipo do solo, inclinação (...) sobre coberturas vegetais. O objetivo é observar as informações de cada localidade e treinar uma rede neural para classificar o tipo de cobertura vegetal presente, predominantemente, na região de coleta de dados.\n","\n","\n","Mais informações sobre o conjunto de dados: https://archive.ics.uci.edu/ml/datasets/Covertype\n","\n","\n","Para carregar esse conjunto de dados iremos utilizar a função `fetch_covtype()`, essa função irá realizar o download dos dados, então é normal que ela demore um pouco para terminar a sua execução."],"metadata":{"id":"v2Br8SqZkUjA"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_covtype\n","\n","# Carregando o conjunto de dados para a memoria\n","data, target = fetch_covtype(return_X_y = True, as_frame = True)"],"metadata":{"id":"r84DZrgblDmb","executionInfo":{"status":"error","timestamp":1639592408022,"user_tz":180,"elapsed":29920,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/","height":398},"outputId":"b1eb34d0-4a8b-44de-d136-0b09bf3f0679"},"execution_count":38,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-d3023866ef78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Carregando o conjunto de dados para a memoria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_covtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_X_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/datasets/_covtype.py\u001b[0m in \u001b[0;36mfetch_covtype\u001b[0;34m(data_home, download_if_missing, random_state, shuffle, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovtype_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mXy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;31m# delete archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2208\u001b[0m                         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musemask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Podemos observar que esse dataset é o maior dentre os que já lidamos até agora: ele possui quase 600 mil amostras (datasets com esse tamanho não são incomuns). Podemos realizar os mesmos procedimentos de antes para obtermos informações sobre os dados:"],"metadata":{"id":"kUjnoSI1l2gA"}},{"cell_type":"code","source":["# verificando informações sobre os atributos utilizados no treinamento\n","data.describe()"],"metadata":{"id":"FFVd4h7mmZeX","executionInfo":{"status":"ok","timestamp":1639575760394,"user_tz":180,"elapsed":524,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/","height":320},"outputId":"9a193b4e-4224-41bd-ab25-fec42877111f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Elevation</th>\n","      <th>Aspect</th>\n","      <th>Slope</th>\n","      <th>Horizontal_Distance_To_Hydrology</th>\n","      <th>Vertical_Distance_To_Hydrology</th>\n","      <th>Horizontal_Distance_To_Roadways</th>\n","      <th>Hillshade_9am</th>\n","      <th>Hillshade_Noon</th>\n","      <th>Hillshade_3pm</th>\n","      <th>Horizontal_Distance_To_Fire_Points</th>\n","      <th>Wilderness_Area_0</th>\n","      <th>Wilderness_Area_1</th>\n","      <th>Wilderness_Area_2</th>\n","      <th>Wilderness_Area_3</th>\n","      <th>Soil_Type_0</th>\n","      <th>Soil_Type_1</th>\n","      <th>Soil_Type_2</th>\n","      <th>Soil_Type_3</th>\n","      <th>Soil_Type_4</th>\n","      <th>Soil_Type_5</th>\n","      <th>Soil_Type_6</th>\n","      <th>Soil_Type_7</th>\n","      <th>Soil_Type_8</th>\n","      <th>Soil_Type_9</th>\n","      <th>Soil_Type_10</th>\n","      <th>Soil_Type_11</th>\n","      <th>Soil_Type_12</th>\n","      <th>Soil_Type_13</th>\n","      <th>Soil_Type_14</th>\n","      <th>Soil_Type_15</th>\n","      <th>Soil_Type_16</th>\n","      <th>Soil_Type_17</th>\n","      <th>Soil_Type_18</th>\n","      <th>Soil_Type_19</th>\n","      <th>Soil_Type_20</th>\n","      <th>Soil_Type_21</th>\n","      <th>Soil_Type_22</th>\n","      <th>Soil_Type_23</th>\n","      <th>Soil_Type_24</th>\n","      <th>Soil_Type_25</th>\n","      <th>Soil_Type_26</th>\n","      <th>Soil_Type_27</th>\n","      <th>Soil_Type_28</th>\n","      <th>Soil_Type_29</th>\n","      <th>Soil_Type_30</th>\n","      <th>Soil_Type_31</th>\n","      <th>Soil_Type_32</th>\n","      <th>Soil_Type_33</th>\n","      <th>Soil_Type_34</th>\n","      <th>Soil_Type_35</th>\n","      <th>Soil_Type_36</th>\n","      <th>Soil_Type_37</th>\n","      <th>Soil_Type_38</th>\n","      <th>Soil_Type_39</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","      <td>581012.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2959.365301</td>\n","      <td>155.656807</td>\n","      <td>14.103704</td>\n","      <td>269.428217</td>\n","      <td>46.418855</td>\n","      <td>2350.146611</td>\n","      <td>212.146049</td>\n","      <td>223.318716</td>\n","      <td>142.528263</td>\n","      <td>1980.291226</td>\n","      <td>0.448865</td>\n","      <td>0.051434</td>\n","      <td>0.436074</td>\n","      <td>0.063627</td>\n","      <td>0.005217</td>\n","      <td>0.012952</td>\n","      <td>0.008301</td>\n","      <td>0.021335</td>\n","      <td>0.002749</td>\n","      <td>0.011316</td>\n","      <td>0.000181</td>\n","      <td>0.000308</td>\n","      <td>0.001974</td>\n","      <td>0.056168</td>\n","      <td>0.021359</td>\n","      <td>0.051584</td>\n","      <td>0.030001</td>\n","      <td>0.001031</td>\n","      <td>0.000005</td>\n","      <td>0.004897</td>\n","      <td>0.005890</td>\n","      <td>0.003268</td>\n","      <td>0.006921</td>\n","      <td>0.015936</td>\n","      <td>0.001442</td>\n","      <td>0.057439</td>\n","      <td>0.099399</td>\n","      <td>0.036622</td>\n","      <td>0.000816</td>\n","      <td>0.004456</td>\n","      <td>0.001869</td>\n","      <td>0.001628</td>\n","      <td>0.198356</td>\n","      <td>0.051927</td>\n","      <td>0.044175</td>\n","      <td>0.090392</td>\n","      <td>0.077716</td>\n","      <td>0.002773</td>\n","      <td>0.003255</td>\n","      <td>0.000205</td>\n","      <td>0.000513</td>\n","      <td>0.026803</td>\n","      <td>0.023762</td>\n","      <td>0.015060</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>279.984734</td>\n","      <td>111.913721</td>\n","      <td>7.488242</td>\n","      <td>212.549356</td>\n","      <td>58.295232</td>\n","      <td>1559.254870</td>\n","      <td>26.769889</td>\n","      <td>19.768697</td>\n","      <td>38.274529</td>\n","      <td>1324.195210</td>\n","      <td>0.497379</td>\n","      <td>0.220882</td>\n","      <td>0.495897</td>\n","      <td>0.244087</td>\n","      <td>0.072039</td>\n","      <td>0.113066</td>\n","      <td>0.090731</td>\n","      <td>0.144499</td>\n","      <td>0.052356</td>\n","      <td>0.105775</td>\n","      <td>0.013442</td>\n","      <td>0.017550</td>\n","      <td>0.044387</td>\n","      <td>0.230245</td>\n","      <td>0.144579</td>\n","      <td>0.221186</td>\n","      <td>0.170590</td>\n","      <td>0.032092</td>\n","      <td>0.002272</td>\n","      <td>0.069804</td>\n","      <td>0.076518</td>\n","      <td>0.057077</td>\n","      <td>0.082902</td>\n","      <td>0.125228</td>\n","      <td>0.037950</td>\n","      <td>0.232681</td>\n","      <td>0.299197</td>\n","      <td>0.187833</td>\n","      <td>0.028551</td>\n","      <td>0.066605</td>\n","      <td>0.043193</td>\n","      <td>0.040318</td>\n","      <td>0.398762</td>\n","      <td>0.221879</td>\n","      <td>0.205483</td>\n","      <td>0.286743</td>\n","      <td>0.267725</td>\n","      <td>0.052584</td>\n","      <td>0.056957</td>\n","      <td>0.014310</td>\n","      <td>0.022641</td>\n","      <td>0.161508</td>\n","      <td>0.152307</td>\n","      <td>0.121791</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1859.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-173.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2809.000000</td>\n","      <td>58.000000</td>\n","      <td>9.000000</td>\n","      <td>108.000000</td>\n","      <td>7.000000</td>\n","      <td>1106.000000</td>\n","      <td>198.000000</td>\n","      <td>213.000000</td>\n","      <td>119.000000</td>\n","      <td>1024.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2996.000000</td>\n","      <td>127.000000</td>\n","      <td>13.000000</td>\n","      <td>218.000000</td>\n","      <td>30.000000</td>\n","      <td>1997.000000</td>\n","      <td>218.000000</td>\n","      <td>226.000000</td>\n","      <td>143.000000</td>\n","      <td>1710.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3163.000000</td>\n","      <td>260.000000</td>\n","      <td>18.000000</td>\n","      <td>384.000000</td>\n","      <td>69.000000</td>\n","      <td>3328.000000</td>\n","      <td>231.000000</td>\n","      <td>237.000000</td>\n","      <td>168.000000</td>\n","      <td>2550.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3858.000000</td>\n","      <td>360.000000</td>\n","      <td>66.000000</td>\n","      <td>1397.000000</td>\n","      <td>601.000000</td>\n","      <td>7117.000000</td>\n","      <td>254.000000</td>\n","      <td>254.000000</td>\n","      <td>254.000000</td>\n","      <td>7173.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Elevation         Aspect  ...   Soil_Type_38   Soil_Type_39\n","count  581012.000000  581012.000000  ...  581012.000000  581012.000000\n","mean     2959.365301     155.656807  ...       0.023762       0.015060\n","std       279.984734     111.913721  ...       0.152307       0.121791\n","min      1859.000000       0.000000  ...       0.000000       0.000000\n","25%      2809.000000      58.000000  ...       0.000000       0.000000\n","50%      2996.000000     127.000000  ...       0.000000       0.000000\n","75%      3163.000000     260.000000  ...       0.000000       0.000000\n","max      3858.000000     360.000000  ...       1.000000       1.000000\n","\n","[8 rows x 54 columns]"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["# verificando a quantidade de amostras por classe (target)\n","target.value_counts()"],"metadata":{"id":"xFB9Bp3Fmvgt","executionInfo":{"status":"ok","timestamp":1639575760395,"user_tz":180,"elapsed":18,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fbb3e6d-b85a-44a1-b45c-af2843550585"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    283301\n","1    211840\n","3     35754\n","7     20510\n","6     17367\n","5      9493\n","4      2747\n","Name: Cover_Type, dtype: int64"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","source":["**Atenção!**: Observe o seguinte: neste conjunto de dados temos muito mais amostras das classes 2 e 1 do que 4, 5 e 6. Isso faz com que o conjunto de dados seja **desbalanceado**, ou seja, há um diferença grande na participação percentual de cada classe na composição do conjunto de dados.\n","\n","Durante o treinamento devemos considerar esse desbalanceamento no momento de separar as amostras para teste e treinamento, a ideia é tentar preservar a mesma porcentagem de amostras em cada uma das classes nos conjuntos de treinamento e teste.\n","\n","-------\n","\n","**Exemplo:** Imagine um conjunto de dados com 100 amostras e 2 classes. Dentre essas classes há 80 amostras da classe positiva e 20 da classe negativa, ou seja, o conjunto de dados está desbalanceado. Para que o treinamento e teste sejam conduzidos de maneira correta precisamos que nos conjuntos de teste e treinamento a porcentagem de amostras da classe positiva sejam de 80% positiva para 20% negativa. Dessa forma, se formos dividir esse conjunto de 100 amostras e 90% treinamento e 10% teste teremos:\n","\n","- conjunto de treinamento com 90 amostras nas quais 72 são da classe positiva e 18 são da classe negativa:\n","\\begin{equation}\n","    \\text{em 90 amostras} \\rightarrow \\dfrac{72}{18} \n","\\end{equation}\n","\n","- conjunto de teste com 10 amostras nas quais 8 são da classe positiva e 2 são da classe negativa:\n","\\begin{equation}\n","    \\text{em 10 amosras} \\rightarrow \\dfrac{8}{2} \n","\\end{equation}\n","\n","Assim preservamos a diferença relativa entre as classes nos conjuntos:\n","\n","\\begin{equation}\n","    \\dfrac{72}{18} = \\dfrac{8}{2} = \\dfrac{80}{20}\n","\\end{equation}\n","\n","A este processo damos o nome de **Estratificação**.\n","\n"],"metadata":{"id":"9HcyPdP4m4uy"}},{"cell_type":"code","source":["# se temos 7 classes, os valores das classes devem ser [0, 6], mas os dados originais tem \n","# esses valores nos intervalos [1, 7].\n","corrected_target = target.apply(lambda classe: classe - 1)\n","\n","\n","# separação entre treinamento e teste\n","# note que podemos passar qual é o atributo em relação ao qual \n","# a estratificação deve ser feita por meio do argumento `stratify`:\n","xtrain, xtest, ytrain, ytest = train_test_split(data, corrected_target,\n","                                                stratify = target,\n","                                                shuffle = True,\n","                                                train_size = 0.9)\n","\n","# normaliação dos dados \n","data_scaler = MinMaxScaler()\n","\n","norm_xtrain = data_scaler.fit_transform(xtrain)\n","norm_xtest = data_scaler.transform(xtest)"],"metadata":{"id":"UiP9MV89r2YU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scikit-Learn"],"metadata":{"id":"1pSzMFEFt3UK"}},{"cell_type":"code","source":["# essa demora bastante...\n","rede_neural = MLPClassifier(hidden_layer_sizes = (300, 300, 150),\n","                            solver = 'adam',\n","                            activation = 'relu',\n","                            early_stopping = True,\n","                            max_iter = 30,\n","                            verbose = True, # retire essa linha para esconder o progresso do treinamento\n","                            n_iter_no_change = 4,\n","                            alpha = 1e-5)\n","\n","rede_neural.fit(norm_xtrain, ytrain)"],"metadata":{"id":"lQnYoQKft9yK","executionInfo":{"status":"ok","timestamp":1639577000388,"user_tz":180,"elapsed":982494,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cfa3a23-6464-40d2-a1dc-4700e2c3d8e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.59452875\n","Validation score: 0.779694\n","Iteration 2, loss = 0.46902609\n","Validation score: 0.814308\n","Iteration 3, loss = 0.40423156\n","Validation score: 0.842210\n","Iteration 4, loss = 0.36364102\n","Validation score: 0.851638\n","Iteration 5, loss = 0.33331306\n","Validation score: 0.860033\n","Iteration 6, loss = 0.30976355\n","Validation score: 0.877799\n","Iteration 7, loss = 0.29208537\n","Validation score: 0.879444\n","Iteration 8, loss = 0.27600019\n","Validation score: 0.890593\n","Iteration 9, loss = 0.26269423\n","Validation score: 0.890899\n","Iteration 10, loss = 0.25150093\n","Validation score: 0.894494\n","Iteration 11, loss = 0.24251918\n","Validation score: 0.900193\n","Iteration 12, loss = 0.23349704\n","Validation score: 0.905471\n","Iteration 13, loss = 0.22571200\n","Validation score: 0.906122\n","Iteration 14, loss = 0.21841969\n","Validation score: 0.909965\n","Iteration 15, loss = 0.21235770\n","Validation score: 0.902909\n","Iteration 16, loss = 0.20851540\n","Validation score: 0.913369\n","Iteration 17, loss = 0.20243735\n","Validation score: 0.912968\n","Iteration 18, loss = 0.19725698\n","Validation score: 0.919011\n","Iteration 19, loss = 0.19308374\n","Validation score: 0.913255\n","Iteration 20, loss = 0.18912511\n","Validation score: 0.920981\n","Iteration 21, loss = 0.18563556\n","Validation score: 0.920636\n","Iteration 22, loss = 0.18139082\n","Validation score: 0.920713\n","Iteration 23, loss = 0.17946288\n","Validation score: 0.920082\n","Iteration 24, loss = 0.17579728\n","Validation score: 0.922185\n","Iteration 25, loss = 0.17333562\n","Validation score: 0.918189\n","Iteration 26, loss = 0.17035810\n","Validation score: 0.925991\n","Iteration 27, loss = 0.16694117\n","Validation score: 0.925513\n","Iteration 28, loss = 0.16464877\n","Validation score: 0.922472\n","Iteration 29, loss = 0.16336489\n","Validation score: 0.923123\n","Iteration 30, loss = 0.16130678\n","Validation score: 0.932436\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(alpha=1e-05, early_stopping=True,\n","              hidden_layer_sizes=(300, 300, 150), max_iter=30,\n","              n_iter_no_change=4, verbose=True)"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["classes_esperadas, classes_preditas = verify_performance_classification(norm_xtrain,\n","                                                                        norm_xtest,\n","                                                                        ytrain,\n","                                                                        ytest,\n","                                                                        rede_neural)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1639577010284,"user_tz":180,"elapsed":9896,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"id":"s9SFxZY4zuZ0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1eca3c31-d6a9-4515-902c-fc9c4bde2f19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------TESTE------\n","Acurácia: \t= 0.9313792984750955\n","Recall \t\t= 0.9150183563309469\n","F1 Score \t= 0.9033800500186919\n","\n","------TREINAMENTO------\n","Acurácia: \t= 0.9403759729207704\n","Recall \t\t= 0.9294624569431464\n","F1 Score \t= 0.9204568576948284\n"]}]},{"cell_type":"markdown","source":["### Keras/Tensorflow\n","\n","Novamente, lembre-se de que devemos modificar a definição das redes neurais para que elas se ajustem à tarefa de classificação. Devemos mudar o número de neurôios na camada de saída, a função de ativação da camada de saída e a função de custo (parâmetro `loss` no momento da compilação do modelo)."],"metadata":{"id":"Lpsc4PlOv67E"}},{"cell_type":"code","source":["rede_neural_keras = keras.Sequential([\n","    keras.layers.Dense(300, activation = 'relu', kernel_initializer = 'he_normal'),\n","    keras.layers.Dense(300, activation = 'relu', kernel_initializer = 'he_normal'),\n","    keras.layers.Dense(150, activation = 'relu', kernel_initializer = 'he_normal'),\n","    keras.layers.Dense(50, activation = 'relu', kernel_initializer = 'he_normal'),\n","\n","    # camada de saída com a mesma quantidade de neurônios igual a quantidade de classes\n","    keras.layers.Dense(7, activation = 'softmax'),\n","])\n","\n","rede_neural_keras.compile(\n","    loss = 'sparse_categorical_crossentropy',\n","    optimizer = 'nadam',\n","    metrics = ['accuracy'],\n",")\n","\n","rede_neural_keras.fit(norm_xtrain, ytrain,\n","                      epochs = 30,\n","                      validation_split = 0.05,\n","                      callbacks = keras.callbacks.EarlyStopping(patience = 4))"],"metadata":{"id":"5wIwkFHrwvuf","executionInfo":{"status":"ok","timestamp":1639578259500,"user_tz":180,"elapsed":1249217,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"100e4d75-7286-427d-b1d8-c7bb8c74099e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","15524/15524 [==============================] - 75s 5ms/step - loss: 0.5042 - accuracy: 0.7830 - val_loss: 0.4139 - val_accuracy: 0.8226\n","Epoch 2/30\n","15524/15524 [==============================] - 74s 5ms/step - loss: 0.3580 - accuracy: 0.8498 - val_loss: 0.3225 - val_accuracy: 0.8658\n","Epoch 3/30\n","15524/15524 [==============================] - 75s 5ms/step - loss: 0.3028 - accuracy: 0.8741 - val_loss: 0.2914 - val_accuracy: 0.8806\n","Epoch 4/30\n","15524/15524 [==============================] - 72s 5ms/step - loss: 0.2703 - accuracy: 0.8884 - val_loss: 0.2737 - val_accuracy: 0.8893\n","Epoch 5/30\n","15524/15524 [==============================] - 76s 5ms/step - loss: 0.2496 - accuracy: 0.8973 - val_loss: 0.2400 - val_accuracy: 0.9019\n","Epoch 6/30\n","15524/15524 [==============================] - 74s 5ms/step - loss: 0.2336 - accuracy: 0.9040 - val_loss: 0.2378 - val_accuracy: 0.9050\n","Epoch 7/30\n","15524/15524 [==============================] - 74s 5ms/step - loss: 0.2216 - accuracy: 0.9092 - val_loss: 0.2316 - val_accuracy: 0.9062\n","Epoch 8/30\n","15524/15524 [==============================] - 76s 5ms/step - loss: 0.2114 - accuracy: 0.9136 - val_loss: 0.2138 - val_accuracy: 0.9149\n","Epoch 9/30\n","15524/15524 [==============================] - 80s 5ms/step - loss: 0.2036 - accuracy: 0.9169 - val_loss: 0.2177 - val_accuracy: 0.9123\n","Epoch 10/30\n","15524/15524 [==============================] - 78s 5ms/step - loss: 0.1964 - accuracy: 0.9198 - val_loss: 0.2078 - val_accuracy: 0.9137\n","Epoch 11/30\n","15524/15524 [==============================] - 77s 5ms/step - loss: 0.1897 - accuracy: 0.9226 - val_loss: 0.2067 - val_accuracy: 0.9206\n","Epoch 12/30\n","15524/15524 [==============================] - 72s 5ms/step - loss: 0.1845 - accuracy: 0.9249 - val_loss: 0.2251 - val_accuracy: 0.9123\n","Epoch 13/30\n","15524/15524 [==============================] - 69s 4ms/step - loss: 0.1797 - accuracy: 0.9270 - val_loss: 0.1834 - val_accuracy: 0.9290\n","Epoch 14/30\n","15524/15524 [==============================] - 70s 5ms/step - loss: 0.1754 - accuracy: 0.9290 - val_loss: 0.2128 - val_accuracy: 0.9197\n","Epoch 15/30\n","15524/15524 [==============================] - 68s 4ms/step - loss: 0.1724 - accuracy: 0.9297 - val_loss: 0.1918 - val_accuracy: 0.9266\n","Epoch 16/30\n","15524/15524 [==============================] - 70s 5ms/step - loss: 0.1693 - accuracy: 0.9316 - val_loss: 0.2402 - val_accuracy: 0.9100\n","Epoch 17/30\n","15524/15524 [==============================] - 69s 4ms/step - loss: 0.1663 - accuracy: 0.9330 - val_loss: 0.1880 - val_accuracy: 0.9313\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f878b8ce8d0>"]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["classes_esperadas, classes_preditas = verify_performance_classification(norm_xtrain,\n","                                                                        norm_xtest,\n","                                                                        ytrain,\n","                                                                        ytest,\n","                                                                        rede_neural)"],"metadata":{"id":"66pI4xgTmwco"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Salvando e Carregando Modelos Treinados\n","\n","Agora que já temos uma ideia geral de como treinar as Redes Neurais, é interessante que elas sejam armazenadas em um arquivo para que possam ser utilziadas no futuro para a tarefa para a qual foram treinadas. Caso contrário do que serviria apenas treiná-las se não vamos utilizá-las depois?\n","\n","O processo para salvar e carregar as redes tanto utilizando Keras quando o Scikit-Learn é bastante parecido e simples:"],"metadata":{"id":"4Wbx7EHGj1zB"}},{"cell_type":"markdown","source":["## Scikit-Learn\n","\n","Para salvar e carregar os modelos treinados como Scikit-Learn devemos utilizar o pacote `Joblib` (como vimos no dia anterior, o joblib pode ser utilizado para salvar praticamente qualquer objeto do Python). Para salvar utilizamos:\n","\n","Documentação (`dump`): https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html\n","\n","Documentação (`load`): https://joblib.readthedocs.io/en/latest/generated/joblib.load.html#joblib.load"],"metadata":{"id":"63_XngqV0Hzw"}},{"cell_type":"code","source":["import joblib\n","\n","# salvando a rede neural treinada em um arquivo\n","joblib.dump(value = rede_neural, filename = \"minha_rede_neural_do_scikit.dat\")\n","\n","# carregando uma rede neural treinada para um \n","rede_neural_treinada = joblib.load('minha_outra_rede_neural.dat')"],"metadata":{"id":"baIu4l4q0qhU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Keras/Tensorflow\n","\n","Carregar e salvar modelos com o Keras é igualmente simples:\n","\n","A única ressalva é que os modelos salvos e carregados pelo Keras devem todos estar no formato `.h5`, tirando essa pequena diferença o processo é praticamente o mesmo (e não requer nenhuma biblioteca de terceiros para salvar e carregar):\n","\n","Documentação: https://keras.io/api/models/model_saving_apis/"],"metadata":{"id":"Qwjw2ob71n7M"}},{"cell_type":"code","source":["# salvando a rede treinada com o keras \n","rede_neural_keras.save(\"rede_treinada_com_keras.h5\")\n","\n","# carregando uma outra rede neural treinadao com o keras\n","rede_neural_keras = keras.models.load_model(\"outra_rede_do_keras.h5\")"],"metadata":{"id":"YDxorXsJ2Tyr","executionInfo":{"status":"error","timestamp":1639580024268,"user_tz":180,"elapsed":357,"user":{"displayName":"Enzo Laragnoit Fernandes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoUKWJkB9XSNwrUAkDKiU1hElefEtXYdDO4lUk=s64","userId":"06738554765111214396"}},"colab":{"base_uri":"https://localhost:8080/","height":362},"outputId":"0c55bd03-4eb4-4413-f29e-ba9ba2779d21"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-131-cea9f9f6d971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# carregando uma outra rede neural treinadao com o keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrede_neural_keras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outra_rede_do_keras.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             raise ImportError(\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at outra_rede_do_keras.h5"]}]}]}